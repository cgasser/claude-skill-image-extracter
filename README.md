# Ollama Vision Image Analyzer

Lokale Bildanalyse mit Ollama Vision Models fÃ¼r Claude Code. Analysiere Bilder, Screenshots und Dokumente ohne externe APIs - alles lokal auf deinem Rechner.

## âœ¨ Features

- ğŸ–¼ï¸ **Automatische Format-Erkennung** - Keine Dateiendung nÃ¶tig (.png, .jpg, .jpeg, .gif, .webp, .bmp, .tiff)
- ğŸ¯ **Custom Prompts** - Stelle spezifische Fragen an das Bild
- ğŸ”’ **100% Lokal & Privat** - Bilder verlassen nie deinen Computer
- âš¡ **Schnell** - Nutzt lokales Ollama qwen3-vl:4b Modell
- ğŸ› ï¸ **Zwei Modi** - CLI-Tool oder MCP-Server

## ğŸ“¦ Installation

### Voraussetzungen

1. **Ollama installieren**:
   ```bash
   # macOS/Linux
   curl -fsSL https://ollama.com/install.sh | sh

   # oder von https://ollama.com/download
   ```

2. **Vision Model herunterladen**:
   ```bash
   ollama pull qwen3-vl:4b
   ```

3. **Python-AbhÃ¤ngigkeiten installieren**:
   ```bash
   pip install -r requirements.txt
   ```

## ğŸš€ Verwendung

### 1. Als CLI-Tool

```bash
# Einfache Analyse
python3 main.py bild.jpg

# Ohne Dateiendung (wird automatisch erkannt)
python3 main.py ~/Desktop/screenshot

# Mit eigenem Prompt
python3 main.py rechnung.png "Extrahiere alle BetrÃ¤ge und Rechnungsnummern"
```

### 2. Als Claude Code Skill

Installiere den Skill in Claude Code:

```bash
# Verlinke oder kopiere das Skill
ln -s ~/repo/claude-skill-image-extracter ~/.claude/skills/ollama-vision
```

Dann in Claude Code:

```
/ollama-vision ~/Desktop/Bildschirmfoto
```

### 3. Als MCP-Server

FÃ¼ge in `~/.claude/mcp_settings.json` hinzu:

```json
{
  "mcpServers": {
    "ollama-vision": {
      "command": "python3",
      "args": [
        "/Users/DEIN_USERNAME/repo/claude-skill-image-extracter/mcp_image_extract.py"
      ]
    }
  }
}
```

## ğŸ“– Beispiele

### Textextraktion
```bash
python3 main.py dokument.png "Extrahiere allen Text"
```

### Formular-Analyse
```bash
python3 main.py formular.jpg "Liste alle Felder und ihre Werte auf"
```

### Screenshot-Beschreibung
```bash
python3 main.py screenshot.png
# Verwendet Standard-Prompt: "Was ist auf diesem Bild zu sehen? Beschreibe es detailliert."
```

## ğŸ—ï¸ Projekt-Struktur

```
claude-skill-image-extracter/
â”œâ”€â”€ main.py                  # CLI-Tool (empfohlen)
â”œâ”€â”€ mcp_image_extract.py     # MCP-Server-Variante
â”œâ”€â”€ SKILL.md                 # Skill-Beschreibung fÃ¼r Claude Code
â”œâ”€â”€ CLAUDE.md                # Diese Projektdokumentation
â”œâ”€â”€ README.md                # Nutzer-Dokumentation
â”œâ”€â”€ requirements.txt         # Python-AbhÃ¤ngigkeiten
â”œâ”€â”€ alternative/             # Referenzen fÃ¼r erweiterte OCR-LÃ¶sungen
â””â”€â”€ test_data/              # Beispiel-Testbilder (optional)
```

## ğŸ¯ Verwendete Technologien

- **[Ollama](https://ollama.com/)** - Lokale LLM-Runtime
- **qwen3-vl:4b** - Vision Language Model fÃ¼r Bildanalyse
- **Python 3.8+** - Programmiersprache
- **FastMCP** - Model Context Protocol Server (optional)

## ğŸ”§ Konfiguration

Das Skript verwendet standardmÃ¤ÃŸig:
- **Modell**: `qwen3-vl:4b`
- **Ollama Host**: `http://localhost:11434`

Um ein anderes Modell zu verwenden, editiere `main.py` oder `mcp_image_extract.py` und Ã¤ndere den `model`-Parameter.

## ğŸ“ Lizenz

MIT License - siehe LICENSE Datei fÃ¼r Details.

## ğŸ¤ Beitragen

Contributions sind willkommen! Bitte Ã¶ffne ein Issue oder Pull Request.

## ğŸ› Fehler melden

Bei Problemen bitte ein Issue auf GitHub erstellen mit:
- Beschreibung des Problems
- Python-Version (`python3 --version`)
- Ollama-Version (`ollama --version`)
- Verwendetes Modell
- Fehlermeldung (falls vorhanden)

## ğŸ’¡ Tipps

- **GrÃ¶ÃŸere Modelle**: FÃ¼r bessere Genauigkeit nutze `llama3.2-vision:11b` (benÃ¶tigt mehr RAM)
- **Schnellere Analyse**: Nutze `moondream` fÃ¼r Edge-Devices
- **Mehrsprachig**: Passe den Prompt an, z.B. "Describe in German..."
